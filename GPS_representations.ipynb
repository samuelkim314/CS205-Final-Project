{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree\n",
    "from sklearn.ensemble import RandomForestClassifier as Forest\n",
    "from sklearn.ensemble import ExtraTreesClassifier as EForest\n",
    "from sklearn.cross_validation import train_test_split as sk_split\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "def Rotate(coords,theta):\n",
    "    out = np.zeros(coords.shape)\n",
    "    out[:,0] = coords[:,0]*np.cos(theta) + coords[:,1]*np.sin(theta)\n",
    "    out[:,1] = -coords[:,0]*np.sin(theta) + coords[:,1]*np.cos(theta)\n",
    "    return out\n",
    "\n",
    "def permutation_importance(tree,test_data,test_target): # estimate variable importance using test data\n",
    "    is_verbose = tree.get_params()['verbose']\n",
    "    tree.set_params(verbose=False)\n",
    "    importances = np.zeros(test_data.shape[1])\n",
    "    original_score = tree.score(test_data,test_target)\n",
    "    for i in xrange(test_data.shape[1]): # scramble each column and get % increase in error rate (Breinman importance)\n",
    "        local = test_data.copy()\n",
    "        np.random.shuffle(local[:,i])\n",
    "        importances[i] = (original_score - tree.score(local,test_target))/(1-original_score)\n",
    "        if is_verbose:\n",
    "            sys.stdout.write('.')\n",
    "            \n",
    "    tree.set_params(verbose=is_verbose)\n",
    "    return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "train_labels = pd.read_csv('train_label.csv')\n",
    "compete_data = pd.read_csv('test.csv')\n",
    "compete_id = compete_data.id\n",
    "N = train_data.shape[0]\n",
    "\n",
    "target = np.zeros(N,dtype=np.int)\n",
    "target[np.array(train_labels['status_group']=='non functional')] = 0\n",
    "target[np.array(train_labels['status_group']=='functional needs repair')] = 1\n",
    "target[np.array(train_labels['status_group']=='functional')] = 2\n",
    "\n",
    "# Manual data processing\n",
    "\n",
    "# Convert date recorded to days since the first recording\n",
    "s = train_data['date_recorded']\n",
    "sc = compete_data['date_recorded']\n",
    "s = s.apply(lambda date_string: np.datetime64(date_string))\n",
    "sc = sc.apply(lambda date_string: np.datetime64(date_string))\n",
    "min_date = s.min()\n",
    "min_datec = sc.min()\n",
    "s = (s-s.min())/np.timedelta64(1,'D')\n",
    "sc = (sc-sc.min())/np.timedelta64(1,'D')\n",
    "train_data['date_recorded']=s\n",
    "compete_data['date_recorded']=sc\n",
    "\n",
    "train_data['region_code'] = 'r'+train_data['region_code'].astype(np.str) # Regions are categorical\n",
    "compete_data['region_code'] = 'r'+compete_data['region_code'].astype(np.str)\n",
    "\n",
    "#                uniform       copy of quantity      unique\n",
    "for feature in ['recorded_by','quantity_group','id','num_private']:\n",
    "    train_data.drop(feature, axis=1, inplace=True) # uniform\n",
    "    compete_data.drop(feature,axis=1,inplace=True)\n",
    "####### EMPRICAL GUESSES\n",
    "## General features that will correlate with higher-detail versions of that feature, e.g. source_type generalized source\n",
    "for feature in ['extraction_type_group','extraction_type_class','payment_type',\n",
    "                'quality_group','source_type','source_class','waterpoint_type_group',\n",
    "                'scheme_management','scheme_name','date_recorded','management_group','basin']:\n",
    "    train_data.drop(feature,axis=1,inplace=True)\n",
    "    compete_data.drop(feature,axis=1,inplace=True)\n",
    "    \n",
    "# Region proxy variables\n",
    "for feature in ['region','region_code','district_code','lga','wpt_name','ward','subvillage']:\n",
    "    train_data.drop(feature,axis=1,inplace=True)\n",
    "    compete_data.drop(feature,axis=1,inplace=True)\n",
    "    \n",
    "# After removing all of the above, the following has mean permutation importances\n",
    "# of <=0.0003 each (as assessed over 15 samples of 50 trees each)\n",
    "#######\n",
    "\n",
    "train_data.fillna(\"was_nan\",inplace=True)\n",
    "compete_data.fillna(\"was_nan\",inplace=True)\n",
    "# Random data to help assess variable importance\n",
    "#train_data['random_1'] = np.random.uniform(0.0,1.0,N)\n",
    "#train_data['random_2'] = np.random.uniform(0.0,1.0,N)\n",
    "#train_data['random_3'] = np.random.binomial(1,0.5,N)\n",
    "#train_data['random_4'] = np.random.binomial(1,0.1,N)\n",
    "\n",
    "\n",
    "# For all categorical data: create binary columns for each category that represents at least p% of the data\n",
    "p = 0.01\n",
    "feature_factors = {}\n",
    "for f in list(train_data.columns):\n",
    "    # Only modify string data\n",
    "    if train_data[f].dtype == np.object:\n",
    "        sizes = train_data.groupby(f).size()/N\n",
    "        sizes.sort(ascending=False)\n",
    "        sizes = sizes[sizes>p]\n",
    "#        print sizes[sizes>p]\n",
    "#        print \"\"\n",
    "#        print f\n",
    "        appended = np.zeros(N,dtype=np.bool)\n",
    "        # The list of categories with at least p% of the training data for feature f\n",
    "        salient_categories = list(sizes.keys())\n",
    "        feature_factors[f] = salient_categories\n",
    "        for cat in salient_categories:\n",
    "            # Append the binary column\n",
    "            train_data[f+'__'+str(cat)] = (train_data[f]==cat)\n",
    "#            print \"\\t\", cat\n",
    "        train_data.drop(f,axis=1,inplace=True)\n",
    "    # Done!\n",
    "    \n",
    "### Perform the same one-hot encoding on the competition data\n",
    "for f in list(compete_data.columns):\n",
    "    # Only modify string (categorical) data\n",
    "    if compete_data[f].dtype == np.object:\n",
    "        for cat in feature_factors[f]:\n",
    "            # Create binary column for trained factors for this feature\n",
    "            compete_data[f+'__'+str(cat)] = (compete_data[f]==cat)\n",
    "        # remove the original column\n",
    "        compete_data.drop(f,axis=1,inplace=True)\n",
    "\n",
    "## After removing all of the above, the following has mean permutation importances\n",
    "## of <=0.0003 each (as assessed over 10 samples of 50 trees each)\n",
    "#for feature in ['funder__Rwssp', 'funder__District Council','funder__0', 'funder__Germany Republi', 'funder__Tcrs',\n",
    "#       'installer__Commu', 'installer__DANIDA', 'installer__0', 'installer__TCRS', 'installer__Central government',\n",
    "#       'installer__CES', 'public_meeting__was_nan', 'permit__was_nan', 'extraction_type__swn 80', \n",
    "#       'extraction_type__afridev', 'extraction_type__ksb', 'management__parastatal',\n",
    "#       'payment__unknown', 'water_quality__soft', 'water_quality__milky', 'quantity__unknown']:\n",
    "#for feature in ['funder__Unicef','funder__0','funder__Kkkt','permit__was_nan',\n",
    "#                'management__water board','water_quality__salty','quantity__unknown',\n",
    "#                'source__lake']:\n",
    "#    train_data.drop(feature,axis=1,inplace=True)\n",
    "#    compete_data.drop(feature,axis=1,inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59400, 97)\n",
      "(14850, 97)\n",
      "(59400, 97)\n",
      "(59400, 3)\n",
      "(59400, 100)\n",
      "(59400, 3)\n",
      "(59400, 103)\n",
      "(59400, 3)\n",
      "(59400, 106)\n",
      "(59400, 3)\n"
     ]
    }
   ],
   "source": [
    "XY = np.array([train_data.longitude,train_data.latitude]).T\n",
    "XYc = np.array([compete_data.longitude,compete_data.latitude]).T\n",
    "for coordinate in ['latitude','longitude']:\n",
    "    train_data.drop(coordinate,axis=1,inplace=True)\n",
    "    compete_data.drop(coordinate,axis=1,inplace=True)\n",
    "\n",
    "r = 5 # total number of rotations (including original coordinates)\n",
    "for i,theta in enumerate(np.linspace(0,np.pi/4,r)):\n",
    "    coords = Rotate(XY, theta)\n",
    "    train_data['longitude_r%d'%(i)] = coords[:,0]\n",
    "    train_data['latitude_r%d'%(i)] = coords[:,1]\n",
    "    coordsc = Rotate(XYc, theta)\n",
    "    compete_data['longitude_r%d'%(i)] = coordsc[:,0]\n",
    "    compete_data['latitude_r%d'%(i)] = coordsc[:,1]\n",
    "\n",
    "data_matrix = train_data.as_matrix().astype(np.float);\n",
    "data_matrix_compete = compete_data.as_matrix().astype(np.float);\n",
    "print data_matrix.shape\n",
    "print data_matrix_compete.shape\n",
    "    \n",
    "# These functions return an array with several columns and a number of\n",
    "# rows equal to the leading dimension of distances and classes.\n",
    "def inverse_distance_class(distances,neighbors,classes):\n",
    "    d = distances.copy()\n",
    "    d[d==0] = np.inf\n",
    "    d = 1.0/d\n",
    "    class_sums = np.zeros((distances.shape[0],3))\n",
    "    for i in range(distances.shape[0]):\n",
    "        for c in range(3):\n",
    "            class_sums[i,c] = np.sum(dists[i,classes[neighbors[i]]==c])\n",
    "    return class_sums\n",
    "\n",
    "def sigmoid_distance_class(distances,neighbors,classes):\n",
    "    class_sums = np.zeros((distances.shape[0],3))\n",
    "    mu = 0.001\n",
    "    kt = 0.001\n",
    "    sig = distances/(1+np.exp((distances-mu)/kt))\n",
    "    for i in range(neighbors.shape[0]):\n",
    "        for c in range(3):\n",
    "            class_sums[i,c] = np.sum(sig[i,classes[neighbors[i]]==c])\n",
    "    return class_sums\n",
    "\n",
    "def long_sigmoid_distance_class(distances,neighbors,classes):\n",
    "    class_sums = np.zeros((distances.shape[0],3))\n",
    "    mu = 0.001\n",
    "    kt = 0.007\n",
    "    sig = distances/(1+np.exp((distances-mu)/kt))\n",
    "    for i in range(neighbors.shape[0]):\n",
    "        for c in range(3):\n",
    "            class_sums[i,c] = np.sum(sig[i,classes[neighbors[i]]==c])\n",
    "    return class_sums\n",
    "\n",
    "def num_neighbors_class(distances,neighbors,classes):\n",
    "    class_sums = np.zeros((neighbors.shape[0],3))\n",
    "    for i in range(neighbors.shape[0]):\n",
    "        for c in range(3):\n",
    "            class_sums[i,c] = np.sum(classes[neighbors[i]]==c)\n",
    "    return class_sums\n",
    "\n",
    "generators = [inverse_distance_class, sigmoid_distance_class,\n",
    "              long_sigmoid_distance_class,num_neighbors_class]\n",
    "#generators = []\n",
    "\n",
    "# Include kNN information using the tuned k=30 results from the initial investigation using kNN classifiers\n",
    "# This gives the forest access to (unnormalized) kNN information\n",
    "knn = KNN(n_neighbors=50)\n",
    "knn.fit(XY,target)\n",
    "\n",
    "dists,neighbors = knn.kneighbors(return_distance=True)\n",
    "for generator in generators:\n",
    "    location_data = generator(dists,neighbors,target)\n",
    "    print data_matrix.shape\n",
    "    print location_data.shape\n",
    "    data_matrix = np.c_[data_matrix,location_data]\n",
    "\n",
    "dists,neighbors = knn.kneighbors(XYc,return_distance=True)\n",
    "for generator in generators:\n",
    "    location_data = generator(dists,neighbors,target)\n",
    "    data_matrix_compete = np.c_[data_matrix_compete,location_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f46eaaa7e10>"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train, data_test, target_train, target_test = sk_split(data_matrix,target,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82205387205387204]\n",
      "[0.82727272727272727]\n",
      "[0.83063973063973062]\n",
      "[0.82946127946127945]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f78f82b0e90>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot accuracy vs number of trees\n",
    "accuracy = []\n",
    "n_est = []\n",
    "forest = Forest(n_estimators=1, criterion='gini', n_jobs=4,verbose=False,max_features=8,bootstrap=True,oob_score=False,\n",
    "                warm_start=True)\n",
    "forest.fit(data_train,target_train)\n",
    "accuracy += [forest.score(data_test,target_test)]\n",
    "n_est += [forest.n_estimators]\n",
    "for i in range(1,5):\n",
    "    forest.set_params(n_estimators=i*20)\n",
    "    forest.fit(data_train,target_train)\n",
    "    accuracy += [forest.score(data_test,target_test)]\n",
    "    n_est += [forest.n_estimators]\n",
    "    print accuracy[-1:]\n",
    "plt.plot(n_est,accuracy,'-^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f78f811f210>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(n_est,accuracy,'--s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            random_state=None, splitter='best')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = Tree(criterion='gini',splitter='best',max_depth=2,min_samples_split=2,min_samples_leaf=1,max_features=None)\n",
    "T.fit(data_matrix,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 22824.   4317.  32259.]\n",
      "[[[  0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n",
      "\n",
      " [[  0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n",
      "\n",
      " [[  1.06780000e+04   2.41700000e+03   9.31700000e+03]]\n",
      "\n",
      " [[  6.09400000e+03   1.86300000e+03   2.27850000e+04]]\n",
      "\n",
      " [[  0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n",
      "\n",
      " [[  5.61500000e+03   3.30000000e+01   1.02000000e+02]]\n",
      "\n",
      " [[  4.37000000e+02   4.00000000e+00   5.50000000e+01]]]\n"
     ]
    }
   ],
   "source": [
    "v = np.sum(T.tree_.value,axis=0).squeeze()\n",
    "print v\n",
    "print T.tree_.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.pie(v,colors=['red','yellow','blue']); plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f78b174a090>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.legend(['non functional','functional needs repair','functional'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 71 108  -2  -2  41  -2  -2]\n",
      "[  0.5  26.5  -2.   -2.    0.5  -2.   -2. ]\n",
      "[ 1  2 -1 -1  5 -1 -1]\n",
      "[ 4  3 -1 -1  6 -1 -1]\n",
      "[ 0.55213908  0.52920599  0.58855467  0.40770155  0.06048813  0.04605768\n",
      "  0.21139275]\n",
      "\n",
      "[ 0.  0.  0.]\n",
      "[ 0.  0.  0.]\n",
      "[ 10678.   2417.   9317.]\n",
      "[  6094.   1863.  22785.]\n",
      "[ 0.  0.  0.]\n",
      "[ 5615.    33.   102.]\n",
      "[ 437.    4.   55.]\n"
     ]
    }
   ],
   "source": [
    "print T.tree_.feature\n",
    "print T.tree_.threshold\n",
    "print T.tree_.children_left\n",
    "print T.tree_.children_right\n",
    "print T.tree_.impurity\n",
    "print\n",
    "for i in range(7):\n",
    "    print T.tree_.value[i].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'extraction_type__nira/tanira'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_data.columns)[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.pie(T.tree_.value[1].squeeze(),colors=['red','yellow','blue']); plt.gca().set_aspect('equal')\n",
    "plt.subplot(1,2,2)\n",
    "plt.pie(T.tree_.value[2].squeeze(),colors=['red','yellow','blue']); plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for p,index in enumerate([2,3,5,6]):\n",
    "    plt.subplot(1,4,p+1)\n",
    "    plt.pie(T.tree_.value[index].squeeze(),colors=['red','yellow','blue']); plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 87)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 200 | elapsed:    0.8s remaining:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83240740740740737"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = EForest(n_estimators=200, criterion='gini', n_jobs=4,verbose=True,max_features='auto',bootstrap=True,\n",
    "                warm_start=False,min_samples_split=2,min_samples_leaf=1,oob_score=True)#,\n",
    "#                class_weight={0:0.5,1:0.5,2:1})\n",
    "forest.fit(data_matrix,target)\n",
    "forest.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    p = np.argmax(forest.oob_decision_function_,axis=1)\n",
    "    print i, \" \", np.sum((target==i)&(p==i))/np.sum(target==i,dtype=np.float)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation 0: 0.000000\n"
     ]
    }
   ],
   "source": [
    "r = 1\n",
    "dists,neighbors = knn.kneighbors(XY,return_distance=True)\n",
    "gps_only = np.zeros((neighbors.shape[0],2*r))\n",
    "for i,theta in enumerate(np.linspace(0,np.pi/4,r)):\n",
    "    print \"Rotation %d: %f\" %(i,theta)\n",
    "    gps_only[:,i*2:(i+1)*2] = Rotate(XY,theta)\n",
    "#for generator in generators:\n",
    "#    gps_only = np.c_[gps_only,generator(dists,neighbors,target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   1 out of   1 | elapsed:    1.4s finished\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.py:379: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46870370370370368"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = Forest(n_estimators=1, criterion='gini',n_jobs=4,verbose=True,\n",
    "                max_features=1, bootstrap=True, oob_score=True,\n",
    "                min_samples_split=2, min_samples_leaf=1)\n",
    "forest.fit(gps_only,target)\n",
    "forest.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   84.1482649842\n",
      "1   9.75214269168\n",
      "2   25.4626615828\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    p = np.argmax(forest.oob_decision_function_,axis=1)\n",
    "    print i, \" \", np.sum((target==i)&(p==i))/np.sum(target==i,dtype=np.float)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301   265\n"
     ]
    }
   ],
   "source": [
    "######################### OVERLAY EACH INDIVIDUAL TREE FROM THE FOREST\n",
    "plt.figure()\n",
    "Ntiles = 8 * 10**4\n",
    "xmin = 33.15; xmax = 33.40\n",
    "ymin = -9.03; ymax = -8.81\n",
    "s = np.sqrt((xmax-xmin)*(ymax-ymin)/Ntiles)\n",
    "nx = np.int((xmax-xmin)/s); ny = np.int((ymax-ymin)/s)\n",
    "print nx, \" \", ny\n",
    "\n",
    "xx,yy = np.meshgrid(np.linspace(xmin, xmax, nx),\n",
    "                    np.linspace(ymin, ymax, ny))\n",
    "cmap = plt.cm.RdYlGn\n",
    "model = forest\n",
    "estimator_alpha = 1.0 / len(model.estimators_)\n",
    "xy = np.c_[xx.ravel(), yy.ravel()]\n",
    "coords = np.zeros((xy.shape[0],2*r))\n",
    "for i,theta in enumerate(np.linspace(0,np.pi/4,r)):\n",
    "    coords[:,2*i:2*i+2] = Rotate(xy,theta)\n",
    "dists,neighbors = knn.kneighbors(xy,return_distance=True)\n",
    "#for generator in generators:\n",
    "#    coords = np.c_[coords,generator(dists,neighbors,target)]\n",
    "for tree in model.estimators_:\n",
    "    Z = tree.predict(coords)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.gca().pcolorfast(np.linspace(xmin,xmax),np.linspace(ymin,ymax),\n",
    "                              Z,cmap=cmap,alpha=estimator_alpha)\n",
    "#    cs = plt.pcolormesh(xx, yy, Z, alpha=estimator_alpha, cmap=cmap,\n",
    "#                        shading='face',edgecolor='None')\n",
    "#    cs.set_linewidths(0)\n",
    "#    cs.set_linestyle('--')\n",
    "#Z = forest.predict(coords)\n",
    "#Z = Z.reshape(xx.shape)\n",
    "#cs = plt.gca().pcolorfast(np.linspace(xmin,xmax),np.linspace(ymin,ymax),\n",
    "#                          Z,cmap=cmap,alpha=0.5)\n",
    "#cs.set_linewidths(0)\n",
    "#cs.set_linestyle('--')\n",
    "\n",
    "\n",
    "plt.gca().set_xlim([xmin,xmax])\n",
    "plt.gca().set_ylim([ymin,ymax])\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.plot(XY[target==0,0],XY[target==0,1],'ro')\n",
    "plt.plot(XY[target==1,0],XY[target==1,1],'yo')\n",
    "plt.plot(XY[target==2,0],XY[target==2,1],'go')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of  81 | elapsed:    0.0s remaining:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:    1.4s finished\n"
     ]
    }
   ],
   "source": [
    "predictions = forest.predict(data_matrix_compete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.gcf().tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_for_export = np.zeros(predictions.shape,dtype=np.object)\n",
    "predictions_for_export[predictions==0] = 'non functional'\n",
    "predictions_for_export[predictions==1] = 'functional needs repair'\n",
    "predictions_for_export[predictions==2] = 'functional'\n",
    "predictions_for_export = np.array([compete_id, predictions_for_export]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14850, 2)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_for_export.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50785, 'non functional'],\n",
       "       [51630, 'functional'],\n",
       "       [17168, 'functional'],\n",
       "       ..., \n",
       "       [28749, 'non functional'],\n",
       "       [33492, 'functional'],\n",
       "       [68707, 'non functional']], dtype=object)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_for_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"submit12.csv\",predictions_for_export,fmt='%s',delimiter=',',header='id,status_group')\n",
    "##### REMEMBER: EDIT CSV FILE TO REMOVE HEADER'S LEADING # AND SPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f473bf82850>]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(); plt.plot(XY[:,0],XY[:,1],'ko',markerfacecolor=None);\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.plot(XYc[:,0],XYc[:,1],'ro',markerfacecolor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### TREE PLOTTING\n",
    "trees = forest.estimators_\n",
    "t = trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_ = t.tree_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37398, 21410, 19189, ...,     1,     7,    26])"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_.n_node_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depth = np.zeros(t_.value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.22219984])"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(0.9,np.log2(t_.children_left.shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f472a4c6b90>]"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(t_.children_left[t_.children_left>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f46f0415ad0>]"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(t_.children_right[t_.children_right>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import collections  as mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_tree(tree,scale = 0.8, angle = np.pi/4):\n",
    "    t_ = tree.tree_\n",
    "    num_nodes = t_.value.shape[0]\n",
    "    left_shift = np.array([-np.sin(angle),-np.cos(angle)])\n",
    "    right_shift = np.array([np.sin(angle),-np.cos(angle)])\n",
    "    levels = np.zeros(num_nodes,dtype=np.int)\n",
    "    locations = np.zeros((num_nodes,2))\n",
    "    segments = []\n",
    "    for node in range(locations.shape[0]):\n",
    "        left = t_.children_left[node]\n",
    "        right = t_.children_right[node]\n",
    "        if left > 0:\n",
    "            levels[[left,right]] = levels[node]+1\n",
    "            reduction = t_.impurity[node]*t_.n_node_samples[node] - t_.impurity[left]*t_.n_node_samples[left] - t_.impurity[right]*t_.n_node_samples[right]\n",
    "            locations[left] = locations[node] + t_.n_node_samples[left]*left_shift\n",
    "            locations[right] = locations[node] + t_.n_node_samples[right]*right_shift\n",
    "#            locations[left] = locations[node] + reduction*left_shift\n",
    "#            locations[right] = locations[node] + reduction*right_shift\n",
    "            segments += [[locations[node],locations[left]]]\n",
    "            segments += [[locations[node],locations[right]]]\n",
    "#    plt.figure()\n",
    "#    lc = mc.LineCollection(segments)\n",
    "#    plt.gca().add_collection(lc)\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x7f9f6a054d90>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments = draw_tree(trees[3],scale=0.5, angle = np.pi/2.5)\n",
    "ax.add_collection(mc.LineCollection(np.array(segments),colors='black'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax=plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lc = mc.LineCollection(np.array(segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x7f9fc07d8750>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.gca().add_collection(lc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax.set_xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree.export_graphviz(trees[3],out_file='tree.dot',feature_names=['lon0','lat0','lon1','lat1','lon2','lat2','inv_n','inv_r','inv_f','sig_n','sig_r','sig_f','Lsig_n','Lsig_r','Lsig_f','N_n','N_r','N_f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
