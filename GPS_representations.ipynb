{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree\n",
    "from sklearn.ensemble import RandomForestClassifier as Forest\n",
    "from sklearn.ensemble import ExtraTreesClassifier as EForest\n",
    "from sklearn.cross_validation import train_test_split as sk_split\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "\n",
    "def Rotate(coords,theta):\n",
    "    out = np.zeros(coords.shape)\n",
    "    out[:,0] = coords[:,0]*np.cos(theta) + coords[:,1]*np.sin(theta)\n",
    "    out[:,1] = -coords[:,0]*np.sin(theta) + coords[:,1]*np.cos(theta)\n",
    "    return out\n",
    "\n",
    "def permutation_importance(tree,test_data,test_target): # estimate variable importance using test data\n",
    "    is_verbose = tree.get_params()['verbose']\n",
    "    tree.set_params(verbose=False)\n",
    "    importances = np.zeros(test_data.shape[1])\n",
    "    original_score = tree.score(test_data,test_target)\n",
    "    for i in xrange(test_data.shape[1]): # scramble each column and get % increase in error rate (Breinman importance)\n",
    "        local = test_data.copy()\n",
    "        np.random.shuffle(local[:,i])\n",
    "        importances[i] = (original_score - tree.score(local,test_target))/(1-original_score)\n",
    "        if is_verbose:\n",
    "            sys.stdout.write('.')\n",
    "            \n",
    "    tree.set_params(verbose=is_verbose)\n",
    "    return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "train_labels = pd.read_csv('train_label.csv')\n",
    "compete_data = pd.read_csv('test.csv')\n",
    "compete_id = compete_data.id\n",
    "N = train_data.shape[0]\n",
    "\n",
    "target = np.zeros(N,dtype=np.int)\n",
    "target[np.array(train_labels['status_group']=='non functional')] = 0\n",
    "target[np.array(train_labels['status_group']=='functional needs repair')] = 1\n",
    "target[np.array(train_labels['status_group']=='functional')] = 2\n",
    "\n",
    "# Manual data processing\n",
    "\n",
    "# Convert date recorded to days since the first recording\n",
    "s = train_data['date_recorded']\n",
    "sc = compete_data['date_recorded']\n",
    "s = s.apply(lambda date_string: np.datetime64(date_string))\n",
    "sc = sc.apply(lambda date_string: np.datetime64(date_string))\n",
    "min_date = s.min()\n",
    "min_datec = sc.min()\n",
    "s = (s-s.min())/np.timedelta64(1,'D')\n",
    "sc = (sc-sc.min())/np.timedelta64(1,'D')\n",
    "train_data['date_recorded']=s\n",
    "compete_data['date_recorded']=sc\n",
    "\n",
    "train_data['region_code'] = 'r'+train_data['region_code'].astype(np.str) # Regions are categorical\n",
    "compete_data['region_code'] = 'r'+compete_data['region_code'].astype(np.str)\n",
    "\n",
    "#                uniform       copy of quantity      unique\n",
    "for feature in ['recorded_by','quantity_group','id','num_private']:\n",
    "    train_data.drop(feature, axis=1, inplace=True) # uniform\n",
    "    compete_data.drop(feature,axis=1,inplace=True)\n",
    "####### EMPRICAL GUESSES\n",
    "## General features that will correlate with higher-detail versions of that feature, e.g. source_type generalized source\n",
    "for feature in ['extraction_type_group','extraction_type_class','payment_type',\n",
    "                'quality_group','source_type','source_class','waterpoint_type_group',\n",
    "                'scheme_management','scheme_name','date_recorded','management_group','basin']:\n",
    "    train_data.drop(feature,axis=1,inplace=True)\n",
    "    compete_data.drop(feature,axis=1,inplace=True)\n",
    "    \n",
    "# Region proxy variables\n",
    "for feature in ['region','region_code','district_code','lga','wpt_name','ward','subvillage']:\n",
    "    train_data.drop(feature,axis=1,inplace=True)\n",
    "    compete_data.drop(feature,axis=1,inplace=True)\n",
    "    \n",
    "# After removing all of the above, the following has mean permutation importances\n",
    "# of <=0.0003 each (as assessed over 15 samples of 50 trees each)\n",
    "#######\n",
    "\n",
    "train_data.fillna(\"was_nan\",inplace=True)\n",
    "compete_data.fillna(\"was_nan\",inplace=True)\n",
    "# Random data to help assess variable importance\n",
    "#train_data['random_1'] = np.random.uniform(0.0,1.0,N)\n",
    "#train_data['random_2'] = np.random.uniform(0.0,1.0,N)\n",
    "#train_data['random_3'] = np.random.binomial(1,0.5,N)\n",
    "#train_data['random_4'] = np.random.binomial(1,0.1,N)\n",
    "\n",
    "\n",
    "# For all categorical data: create binary columns for each category that represents at least p% of the data\n",
    "p = 0.01\n",
    "feature_factors = {}\n",
    "for f in list(train_data.columns):\n",
    "    # Only modify string data\n",
    "    if train_data[f].dtype == np.object:\n",
    "        sizes = train_data.groupby(f).size()/N\n",
    "        sizes.sort(ascending=False)\n",
    "        sizes = sizes[sizes>p]\n",
    "#        print sizes[sizes>p]\n",
    "#        print \"\"\n",
    "#        print f\n",
    "        appended = np.zeros(N,dtype=np.bool)\n",
    "        # The list of categories with at least p% of the training data for feature f\n",
    "        salient_categories = list(sizes.keys())\n",
    "        feature_factors[f] = salient_categories\n",
    "        for cat in salient_categories:\n",
    "            # Append the binary column\n",
    "            train_data[f+'__'+str(cat)] = (train_data[f]==cat)\n",
    "#            print \"\\t\", cat\n",
    "        train_data.drop(f,axis=1,inplace=True)\n",
    "    # Done!\n",
    "    \n",
    "### Perform the same one-hot encoding on the competition data\n",
    "for f in list(compete_data.columns):\n",
    "    # Only modify string (categorical) data\n",
    "    if compete_data[f].dtype == np.object:\n",
    "        for cat in feature_factors[f]:\n",
    "            # Create binary column for trained factors for this feature\n",
    "            compete_data[f+'__'+str(cat)] = (compete_data[f]==cat)\n",
    "        # remove the original column\n",
    "        compete_data.drop(f,axis=1,inplace=True)\n",
    "\n",
    "## After removing all of the above, the following has mean permutation importances\n",
    "## of <=0.0003 each (as assessed over 10 samples of 50 trees each)\n",
    "#for feature in ['funder__Rwssp', 'funder__District Council','funder__0', 'funder__Germany Republi', 'funder__Tcrs',\n",
    "#       'installer__Commu', 'installer__DANIDA', 'installer__0', 'installer__TCRS', 'installer__Central government',\n",
    "#       'installer__CES', 'public_meeting__was_nan', 'permit__was_nan', 'extraction_type__swn 80', \n",
    "#       'extraction_type__afridev', 'extraction_type__ksb', 'management__parastatal',\n",
    "#       'payment__unknown', 'water_quality__soft', 'water_quality__milky', 'quantity__unknown']:\n",
    "#for feature in ['funder__Unicef','funder__0','funder__Kkkt','permit__was_nan',\n",
    "#                'management__water board','water_quality__salty','quantity__unknown',\n",
    "#                'source__lake']:\n",
    "#    train_data.drop(feature,axis=1,inplace=True)\n",
    "#    compete_data.drop(feature,axis=1,inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59400, 97)\n",
      "(14850, 97)\n",
      "(59400, 97)\n",
      "(59400, 3)\n",
      "(59400, 100)\n",
      "(59400, 3)\n",
      "(59400, 103)\n",
      "(59400, 3)\n",
      "(59400, 106)\n",
      "(59400, 3)\n"
     ]
    }
   ],
   "source": [
    "XY = np.array([train_data.longitude,train_data.latitude]).T\n",
    "XYc = np.array([compete_data.longitude,compete_data.latitude]).T\n",
    "for coordinate in ['latitude','longitude']:\n",
    "    train_data.drop(coordinate,axis=1,inplace=True)\n",
    "    compete_data.drop(coordinate,axis=1,inplace=True)\n",
    "\n",
    "r = 5 # total number of rotations (including original coordinates)\n",
    "for i,theta in enumerate(np.linspace(0,np.pi/4,r)):\n",
    "    coords = Rotate(XY, theta)\n",
    "    train_data['longitude_r%d'%(i)] = coords[:,0]\n",
    "    train_data['latitude_r%d'%(i)] = coords[:,1]\n",
    "    coordsc = Rotate(XYc, theta)\n",
    "    compete_data['longitude_r%d'%(i)] = coordsc[:,0]\n",
    "    compete_data['latitude_r%d'%(i)] = coordsc[:,1]\n",
    "\n",
    "data_matrix = train_data.as_matrix().astype(np.float);\n",
    "data_matrix_compete = compete_data.as_matrix().astype(np.float);\n",
    "print data_matrix.shape\n",
    "print data_matrix_compete.shape\n",
    "    \n",
    "# These functions return an array with several columns and a number of\n",
    "# rows equal to the leading dimension of distances and classes.\n",
    "def inverse_distance_class(distances,neighbors,classes):\n",
    "    d = distances.copy()\n",
    "    d[d==0] = np.inf\n",
    "    d = 1.0/d\n",
    "    class_sums = np.zeros((distances.shape[0],3))\n",
    "    for i in range(distances.shape[0]):\n",
    "        for c in range(3):\n",
    "            class_sums[i,c] = np.sum(dists[i,classes[neighbors[i]]==c])\n",
    "    return class_sums\n",
    "\n",
    "def sigmoid_distance_class(distances,neighbors,classes):\n",
    "    class_sums = np.zeros((distances.shape[0],3))\n",
    "    mu = 0.001\n",
    "    kt = 0.001\n",
    "    sig = distances/(1+np.exp((distances-mu)/kt))\n",
    "    for i in range(neighbors.shape[0]):\n",
    "        for c in range(3):\n",
    "            class_sums[i,c] = np.sum(sig[i,classes[neighbors[i]]==c])\n",
    "    return class_sums\n",
    "\n",
    "def long_sigmoid_distance_class(distances,neighbors,classes):\n",
    "    class_sums = np.zeros((distances.shape[0],3))\n",
    "    mu = 0.001\n",
    "    kt = 0.007\n",
    "    sig = distances/(1+np.exp((distances-mu)/kt))\n",
    "    for i in range(neighbors.shape[0]):\n",
    "        for c in range(3):\n",
    "            class_sums[i,c] = np.sum(sig[i,classes[neighbors[i]]==c])\n",
    "    return class_sums\n",
    "\n",
    "def num_neighbors_class(distances,neighbors,classes):\n",
    "    class_sums = np.zeros((neighbors.shape[0],3))\n",
    "    for i in range(neighbors.shape[0]):\n",
    "        for c in range(3):\n",
    "            class_sums[i,c] = np.sum(classes[neighbors[i]]==c)\n",
    "    return class_sums\n",
    "\n",
    "generators = [inverse_distance_class, sigmoid_distance_class,\n",
    "              long_sigmoid_distance_class,num_neighbors_class]\n",
    "#generators = []\n",
    "\n",
    "# Include kNN information using the tuned k=30 results from the initial investigation using kNN classifiers\n",
    "# This gives the forest access to (unnormalized) kNN information\n",
    "knn = KNN(n_neighbors=50)\n",
    "knn.fit(XY,target)\n",
    "\n",
    "dists,neighbors = knn.kneighbors(return_distance=True)\n",
    "for generator in generators:\n",
    "    location_data = generator(dists,neighbors,target)\n",
    "    print data_matrix.shape\n",
    "    print location_data.shape\n",
    "    data_matrix = np.c_[data_matrix,location_data]\n",
    "\n",
    "dists,neighbors = knn.kneighbors(XYc,return_distance=True)\n",
    "for generator in generators:\n",
    "    location_data = generator(dists,neighbors,target)\n",
    "    data_matrix_compete = np.c_[data_matrix_compete,location_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f46eaaa7e10>"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train, data_test, target_train, target_test = sk_split(data_matrix,target,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82003367003367]\n",
      "[0.82794612794612799]\n",
      "[0.83181818181818179]\n",
      "[0.83434343434343439]\n",
      "[0.83181818181818179]\n",
      "[0.8353535353535354]\n",
      "[0.83468013468013469]\n",
      "[0.83333333333333337]\n",
      "[0.83434343434343439]\n",
      "[0.83367003367003367]\n",
      "[0.83333333333333337]\n",
      "[0.83299663299663296]\n",
      "[0.83299663299663296]\n",
      "[0.83383838383838382]\n",
      "[0.83383838383838382]\n",
      "[0.83484848484848484]\n",
      "[0.83468013468013469]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-375-0ac780d6bf8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0maccuracy\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mn_est\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \"\"\"\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[1;31m# for 1d.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    511\u001b[0m                              \u001b[0mbackend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"threading\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_parallel_helper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'predict_proba'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 513\u001b[1;33m             for e in self.estimators_)\n\u001b[0m\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;31m# Reduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    664\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 666\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s.wait(): got it\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Plot accuracy vs number of trees\n",
    "accuracy = []\n",
    "n_est = []\n",
    "forest = Forest(n_estimators=1, criterion='gini', n_jobs=4,verbose=False,max_features=8,bootstrap=True,oob_score=False,\n",
    "                warm_start=True)\n",
    "forest.fit(data_train,target_train)\n",
    "accuracy += [forest.score(data_test,target_test)]\n",
    "n_est += [forest.n_estimators]\n",
    "for i in range(1,150):\n",
    "    forest.set_params(n_estimators=i*20)\n",
    "    forest.fit(data_train,target_train)\n",
    "    accuracy += [forest.score(data_test,target_test)]\n",
    "    n_est += [forest.n_estimators]\n",
    "    print accuracy[-1:]\n",
    "plt.plot(n_est,accuracy,'-^')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f472be6ff10>]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(n_est,accuracy,'--s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59400, 87)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 200 | elapsed:    0.8s remaining:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   10.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83240740740740737"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = EForest(n_estimators=200, criterion='gini', n_jobs=4,verbose=True,max_features='auto',bootstrap=True,\n",
    "                warm_start=False,min_samples_split=2,min_samples_leaf=1,oob_score=True)#,\n",
    "#                class_weight={0:0.5,1:0.5,2:1})\n",
    "forest.fit(data_matrix,target)\n",
    "forest.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    p = np.argmax(forest.oob_decision_function_,axis=1)\n",
    "    print i, \" \", np.sum((target==i)&(p==i))/np.sum(target==i,dtype=np.float)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation 0: 0.000000\n",
      "Rotation 1: 0.392699\n",
      "Rotation 2: 0.785398\n"
     ]
    }
   ],
   "source": [
    "r = 3\n",
    "dists,neighbors = knn.kneighbors(XY,return_distance=True)\n",
    "gps_only = np.zeros((neighbors.shape[0],2*r))\n",
    "for i,theta in enumerate(np.linspace(0,np.pi/4,r)):\n",
    "    print \"Rotation %d: %f\" %(i,theta)\n",
    "    gps_only[:,i*2:(i+1)*2] = Rotate(XY,theta)\n",
    "for generator in generators:\n",
    "    gps_only = np.c_[gps_only,generator(dists,neighbors,target)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 200 | elapsed:    0.3s remaining:   52.7s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:    6.0s finished\n"
     ]
    }
   ],
   "source": [
    "forest = Forest(n_estimators=200, criterion='gini',n_jobs=4,verbose=True,\n",
    "                max_features=1, bootstrap=True, oob_score=True,\n",
    "                min_samples_split=4, min_samples_leaf=1)\n",
    "forest.fit(gps_only,target)\n",
    "forest.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    p = np.argmax(forest.oob_decision_function_,axis=1)\n",
    "    print i, \" \", np.sum((target==i)&(p==i))/np.sum(target==i,dtype=np.float)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################### OVERLAY EACH INDIVIDUAL TREE FROM THE FOREST\n",
    "plt.figure()\n",
    "Ntiles = 8 * 10**4\n",
    "xmin = 33.15; xmax = 33.40\n",
    "ymin = -9.03; ymax = -8.81\n",
    "s = np.sqrt((xmax-xmin)*(ymax-ymin)/Ntiles)\n",
    "nx = np.int((xmax-xmin)/s); ny = np.int((ymax-ymin)/s)\n",
    "print nx, \" \", ny\n",
    "\n",
    "xx,yy = np.meshgrid(np.linspace(xmin, xmax, nx),\n",
    "                    np.linspace(ymin, ymax, ny))\n",
    "cmap = plt.cm.RdYlGn\n",
    "model = forest\n",
    "estimator_alpha = 1.0 / len(model.estimators_)\n",
    "xy = np.c_[xx.ravel(), yy.ravel()]\n",
    "coords = np.zeros((xy.shape[0],2*r))\n",
    "for i,theta in enumerate(np.linspace(0,np.pi/4,r)):\n",
    "    coords[:,2*i:2*i+2] = Rotate(xy,theta)\n",
    "dists,neighbors = knn.kneighbors(xy,return_distance=True)\n",
    "for generator in generators:\n",
    "    coords = np.c_[coords,generator(dists,neighbors,target)]\n",
    "for tree in model.estimators_:\n",
    "    Z = tree.predict(coords)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.gca().pcolorfast(np.linspace(xmin,xmax),np.linspace(ymin,ymax),\n",
    "                              Z,cmap=cmap,alpha=estimator_alpha)\n",
    "#    cs = plt.pcolormesh(xx, yy, Z, alpha=estimator_alpha, cmap=cmap,\n",
    "#                        shading='face',edgecolor='None')\n",
    "#    cs.set_linewidths(0)\n",
    "#    cs.set_linestyle('--')\n",
    "#Z = forest.predict(coords)\n",
    "#Z = Z.reshape(xx.shape)\n",
    "#cs = plt.gca().pcolorfast(np.linspace(xmin,xmax),np.linspace(ymin,ymax),\n",
    "#                          Z,cmap=cmap,alpha=0.5)\n",
    "#cs.set_linewidths(0)\n",
    "#cs.set_linestyle('--')\n",
    "\n",
    "\n",
    "plt.gca().set_xlim([xmin,xmax])\n",
    "plt.gca().set_ylim([ymin,ymax])\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.plot(XY[target==0,0],XY[target==0,1],'ro')\n",
    "plt.plot(XY[target==1,0],XY[target==1,1],'yo')\n",
    "plt.plot(XY[target==2,0],XY[target==2,1],'go')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of  81 | elapsed:    0.0s remaining:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done 400 out of 400 | elapsed:    1.4s finished\n"
     ]
    }
   ],
   "source": [
    "predictions = forest.predict(data_matrix_compete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.gcf().tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_for_export = np.zeros(predictions.shape,dtype=np.object)\n",
    "predictions_for_export[predictions==0] = 'non functional'\n",
    "predictions_for_export[predictions==1] = 'functional needs repair'\n",
    "predictions_for_export[predictions==2] = 'functional'\n",
    "predictions_for_export = np.array([compete_id, predictions_for_export]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14850, 2)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_for_export.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50785, 'non functional'],\n",
       "       [51630, 'functional'],\n",
       "       [17168, 'functional'],\n",
       "       ..., \n",
       "       [28749, 'non functional'],\n",
       "       [33492, 'functional'],\n",
       "       [68707, 'non functional']], dtype=object)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_for_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"submit12.csv\",predictions_for_export,fmt='%s',delimiter=',',header='id,status_group')\n",
    "##### REMEMBER: EDIT CSV FILE TO REMOVE HEADER'S LEADING # AND SPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f473bf82850>]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(); plt.plot(XY[:,0],XY[:,1],'ko',markerfacecolor=None);\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.plot(XYc[:,0],XYc[:,1],'ro',markerfacecolor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
