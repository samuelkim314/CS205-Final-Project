{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as Tree\n",
    "from sklearn.ensemble import RandomForestClassifier as Forest\n",
    "from sklearn.cross_validation import train_test_split as sk_split\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "#%matplotlib qt\n",
    "\n",
    "def permutation_importance(tree,test_data,test_target): # estimate variable importance using test data\n",
    "    is_verbose = tree.get_params()['verbose']\n",
    "    tree.set_params(verbose=False)\n",
    "    importances = np.zeros(test_data.shape[1])\n",
    "    original_score = tree.score(test_data,test_target)\n",
    "    for i in xrange(test_data.shape[1]): # scramble each column and get % increase in error rate (Breinman importance)\n",
    "        local = test_data.copy()\n",
    "        np.random.shuffle(local[:,i])\n",
    "        importances[i] = (original_score - tree.score(local,test_target))/(1-original_score)\n",
    "        if is_verbose:\n",
    "            sys.stdout.write('.')\n",
    "            \n",
    "    tree.set_params(verbose=is_verbose)\n",
    "    return importances\n",
    "\n",
    "def Rotate(coords,theta):\n",
    "    out = np.zeros(coords.shape)\n",
    "    out[:,0] = coords[:,0]*np.cos(theta) + coords[:,1]*np.sin(theta)\n",
    "    out[:,1] = -coords[:,0]*np.sin(theta) + coords[:,1]*np.cos(theta)\n",
    "    return out\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "train_labels = pd.read_csv('train_label.csv')\n",
    "compete_data = pd.read_csv('test.csv')\n",
    "compete_id = compete_data.id\n",
    "N = train_data.shape[0]\n",
    "\n",
    "target = np.zeros(N,dtype=np.int)\n",
    "target[np.array(train_labels['status_group']=='non functional')] = 0\n",
    "target[np.array(train_labels['status_group']=='functional needs repair')] = 1\n",
    "target[np.array(train_labels['status_group']=='functional')] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier as EForest\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def oob_permuation_importance(forest,test_data,test_target):\n",
    "    votes = np.zeros(test_data.shape[0],len(tree.classes_))\n",
    "    perm_votes = np.zeros(test_data.shape[0],tree.n_classes_,test_data.shape[1])\n",
    "    for tree in forest.estimators_:\n",
    "        oob = np.logical_not(tree.indices_)\n",
    "        oob_data = test_data[oob,:].copy()\n",
    "        tree_votes = tree.predict(oob_data)\n",
    "        for i,c in enumerate(tree.classes_):\n",
    "            votes(:)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Manual data processing\n",
    "\n",
    "# Convert date recorded to days since the first recording\n",
    "s = train_data['date_recorded']\n",
    "sc = compete_data['date_recorded']\n",
    "s = s.apply(lambda date_string: np.datetime64(date_string))\n",
    "sc = sc.apply(lambda date_string: np.datetime64(date_string))\n",
    "min_date = s.min()\n",
    "min_datec = sc.min()\n",
    "s = (s-s.min())/np.timedelta64(1,'D')\n",
    "sc = (sc-sc.min())/np.timedelta64(1,'D')\n",
    "train_data['date_recorded']=s\n",
    "compete_data['date_recorded']=sc\n",
    "\n",
    "train_data['region_code'] = 'r'+train_data['region_code'].astype(np.str) # Regions are categorical\n",
    "compete_data['region_code'] = 'r'+compete_data['region_code'].astype(np.str)\n",
    "\n",
    "XY = np.array([train_data.longitude,train_data.latitude]).T\n",
    "XYc = np.array([compete_data.longitude,compete_data.latitude]).T\n",
    "r = 5 # total number of rotations (including original coordinates)\n",
    "for i,theta in enumerate(np.linspace(0,np.pi/4,r)):\n",
    "    if i>0:\n",
    "        coords = Rotate(XY, theta)\n",
    "        train_data['longitude_r%d'%(i)] = coords[:,0]\n",
    "        train_data['latitude_r%d'%(i)] = coords[:,1]\n",
    "        coordsc = Rotate(XYc, theta)\n",
    "        compete_data['longitude_r%d'%(i)] = coordsc[:,0]\n",
    "        compete_data['latitude_r%d'%(i)] = coordsc[:,1]\n",
    "\n",
    "# Include kNN information using the tuned k=30 results from the initial investigation using kNN classifiers\n",
    "# This gives the forest access to (unnormalized) kNN information\n",
    "knn = KNN(n_neighbors=30,weights='distance')\n",
    "knn.fit(XY,target)\n",
    "dists,neighbors = knn.kneighbors(return_distance=True)\n",
    "dists[dists==0]=np.inf\n",
    "dists = 1.0/dists\n",
    "class_sums = np.zeros((XY.shape[0],3))\n",
    "for i in range(XY.shape[0]):\n",
    "    for c in range(3):\n",
    "        class_sums[i,c] = np.sum(dists[i,target[neighbors[i]]==c])\n",
    "for c in range(3):\n",
    "    train_data['knn_%d'%(c)] = class_sums[:,c]\n",
    "\n",
    "dists,neighbors = knn.kneighbors(XYc,return_distance=True)\n",
    "dists[dists==0]=np.inf\n",
    "dists = 1.0/dists\n",
    "class_sums = np.zeros((XYc.shape[0],3))\n",
    "for i in range(XYc.shape[0]):\n",
    "    for c in range(3):\n",
    "        class_sums[i,c] = np.sum(dists[i,target[neighbors[i]]==c])\n",
    "for c in range(3):\n",
    "    compete_data['knn_%d'%(c)] = class_sums[:,c]\n",
    "    \n",
    "    \n",
    "#                uniform       copy of quantity      unique\n",
    "for feature in ['recorded_by','quantity_group','id','num_private']:\n",
    "    train_data.drop(feature, axis=1, inplace=True) # uniform\n",
    "    compete_data.drop(feature,axis=1,inplace=True)\n",
    "####### EMPRICAL GUESSES\n",
    "## General features that will correlate with higher-detail versions of that feature, e.g. source_type generalized source\n",
    "for feature in ['extraction_type_group','extraction_type_class','payment_type',\n",
    "                'quality_group','source_type','source_class','waterpoint_type_group',\n",
    "                'scheme_management','scheme_name','date_recorded','management_group','basin']:\n",
    "    train_data.drop(feature,axis=1,inplace=True)\n",
    "    compete_data.drop(feature,axis=1,inplace=True)\n",
    "    \n",
    "# Region proxy variables\n",
    "for feature in ['region','region_code','district_code','lga','wpt_name','ward','subvillage']:\n",
    "    train_data.drop(feature,axis=1,inplace=True)\n",
    "    compete_data.drop(feature,axis=1,inplace=True)\n",
    "    \n",
    "# After removing all of the above, the following has mean permutation importances\n",
    "# of <=0.0003 each (as assessed over 15 samples of 50 trees each)\n",
    "#######\n",
    "\n",
    "train_data.fillna(\"was_nan\",inplace=True)\n",
    "compete_data.fillna(\"was_nan\",inplace=True)\n",
    "# Random data to help assess variable importance\n",
    "#train_data['random_1'] = np.random.uniform(0.0,1.0,N)\n",
    "#train_data['random_2'] = np.random.uniform(0.0,1.0,N)\n",
    "#train_data['random_3'] = np.random.binomial(1,0.5,N)\n",
    "#train_data['random_4'] = np.random.binomial(1,0.1,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data['knn_0'][0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For all categorical data: create binary columns for each category that represents at least p% of the data\n",
    "p = 0.01\n",
    "feature_factors = {}\n",
    "for f in list(train_data.columns):\n",
    "    # Only modify string data\n",
    "    if train_data[f].dtype == np.object:\n",
    "        sizes = train_data.groupby(f).size()/N\n",
    "        sizes.sort(ascending=False)\n",
    "        sizes = sizes[sizes>p]\n",
    "#        print sizes[sizes>p]\n",
    "        print \"\"\n",
    "        print f\n",
    "        appended = np.zeros(N,dtype=np.bool)\n",
    "        # The list of categories with at least p% of the training data for feature f\n",
    "        salient_categories = list(sizes.keys())\n",
    "        feature_factors[f] = salient_categories\n",
    "        for cat in salient_categories:\n",
    "            # Append the binary column\n",
    "            train_data[f+'__'+str(cat)] = (train_data[f]==cat)\n",
    "            print \"\\t\", cat\n",
    "        train_data.drop(f,axis=1,inplace=True)\n",
    "    # Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Perform the same one-hot encoding on the competition data\n",
    "for f in list(compete_data.columns):\n",
    "    # Only modify string (categorical) data\n",
    "    if compete_data[f].dtype == np.object:\n",
    "        for cat in feature_factors[f]:\n",
    "            # Create binary column for trained factors for this feature\n",
    "            compete_data[f+'__'+str(cat)] = (compete_data[f]==cat)\n",
    "        # remove the original column\n",
    "        compete_data.drop(f,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## After removing all of the above, the following has mean permutation importances\n",
    "## of <=0.0003 each (as assessed over 10 samples of 50 trees each)\n",
    "#for feature in ['funder__Rwssp', 'funder__District Council','funder__0', 'funder__Germany Republi', 'funder__Tcrs',\n",
    "#       'installer__Commu', 'installer__DANIDA', 'installer__0', 'installer__TCRS', 'installer__Central government',\n",
    "#       'installer__CES', 'public_meeting__was_nan', 'permit__was_nan', 'extraction_type__swn 80', \n",
    "#       'extraction_type__afridev', 'extraction_type__ksb', 'management__parastatal',\n",
    "#       'payment__unknown', 'water_quality__soft', 'water_quality__milky', 'quantity__unknown']:\n",
    "for feature in ['funder__Unicef','funder__0','funder__Kkkt','permit__was_nan',\n",
    "                'management__water board','water_quality__salty','quantity__unknown',\n",
    "                'source__lake']:\n",
    "    train_data.drop(feature,axis=1,inplace=True)\n",
    "    compete_data.drop(feature,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59400, 89)\n",
      "(14850, 89)\n"
     ]
    }
   ],
   "source": [
    "data_matrix = train_data.as_matrix().astype(np.float);\n",
    "data_matrix_compete = compete_data.as_matrix().astype(np.float);\n",
    "print data_matrix.shape\n",
    "print data_matrix_compete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train, data_test, target_train, target_test = sk_split(data_matrix,target,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80303030303030298]\n",
      "[0.80808080808080807]\n",
      "[0.8101010101010101]\n",
      "[0.80909090909090908]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-2b56f2d815f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mn_est\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    271\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 273\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    664\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 666\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s.wait(): got it\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Plot accuracy vs number of trees\n",
    "accuracy = []\n",
    "n_est = []\n",
    "forest = Forest(n_estimators=1, criterion='gini', n_jobs=4,verbose=False,max_features=13,bootstrap=True,oob_score=False,\n",
    "                warm_start=True)\n",
    "forest.fit(data_train,target_train)\n",
    "accuracy += [forest.score(data_test,target_test)]\n",
    "n_est += [forest.n_estimators]\n",
    "for i in range(1,20):\n",
    "    forest.set_params(n_estimators=i*20)\n",
    "    forest.fit(data_train,target_train)\n",
    "    accuracy += [forest.score(data_test,target_test)]\n",
    "    n_est += [forest.n_estimators]\n",
    "    print accuracy[-1:]\n",
    "plt.plot(n_est,accuracy,'-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9148c4f4d0>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.legend([.2,.2,.2,.1,.1,.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=10, max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=420, n_jobs=4,\n",
       "            oob_score=True, random_state=None, verbose=False,\n",
       "            warm_start=True)"
      ]
     },
     "execution_count": 933,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.set_params(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() got an unexpected keyword argument 'n_estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-913-c9506345c7a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'n_estimators'"
     ]
    }
   ],
   "source": [
    "forest.fit(data_train,target_train,n_estimators=20,warm_start=True)\n",
    "print forest.score(data_test,target_test)\n",
    "print forest.n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-821-c78cd01f541d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpermutation_importance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mzscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myerr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merror_kw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mecolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'red'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-570-147218481ce3>\u001b[0m in \u001b[0;36mpermutation_importance\u001b[1;34m(tree, test_data, test_target)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mlocal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mimportances\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0moriginal_score\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0moriginal_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_verbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \"\"\"\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[1;31m# for 1d.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    511\u001b[0m                              \u001b[0mbackend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"threading\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_parallel_helper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'predict_proba'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 513\u001b[1;33m             for e in self.estimators_)\n\u001b[0m\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;31m# Reduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    664\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 666\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s.wait(): got it\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pi = permutation_importance(forest,data_test,target_test)\n",
    "current += [pi]\n",
    "zscores = np.sqrt(len(current))*np.mean(current,axis=0)/np.std(current,axis=0)\n",
    "plt.figure()\n",
    "plt.bar(range(len(list(train_data.columns))),np.mean(current,axis=0),yerr=np.std(current,axis=0)/np.sqrt(len(current)),error_kw=dict(ecolor='red'))\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(np.arange(len(list(train_data.columns)))+0.4)\n",
    "ax.set_xticklabels(list(train_data.columns))\n",
    "plt.plot(zscores)\n",
    "bad_features = np.array(train_data.columns)[pi/np.max(pi)<=-0.00]\n",
    "bad_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of  50 | elapsed:    0.2s remaining:    7.5s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=4)]: Done   1 out of  15 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814646464646\n",
      "..............................................................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of  50 | elapsed:    0.2s remaining:    8.7s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=4)]: Done   1 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".0.811531986532\n",
      "..............................................................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of  50 | elapsed:    0.2s remaining:    7.7s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=4)]: Done   1 out of  18 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".0.81734006734\n",
      "..............................................................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of  50 | elapsed:    0.2s remaining:    7.5s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=4)]: Done   1 out of  23 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".0.818097643098\n",
      "..............................................................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of  50 | elapsed:    0.1s remaining:    6.8s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=4)]: Done   1 out of  50 | elapsed:    0.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".0.820538720539\n",
      "................................................................................................"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['funder__World Bank', 'funder__World Vision', 'funder__Unicef',\n",
       "       'funder__District Council', 'funder__0', 'funder__Norad',\n",
       "       'funder__Germany Republi', 'installer__was_nan', 'installer__Commu',\n",
       "       'installer__Hesawa', 'installer__Central government',\n",
       "       'installer__CES', 'permit__True', 'extraction_type__afridev',\n",
       "       'management__water board', 'management__private operator',\n",
       "       'management__parastatal', 'management__water authority',\n",
       "       'management__company', 'payment__pay monthly',\n",
       "       'payment__pay when scheme fails', 'payment__pay annually',\n",
       "       'water_quality__salty', 'quantity__unknown', 'source__spring',\n",
       "       'source__shallow well', 'source__machine dbh', 'source__river',\n",
       "       'source__hand dtw', 'waterpoint_type__improved spring'], dtype=object)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bar plot with standard error bars for permutation importance\n",
    "pi=[]\n",
    "current=[]\n",
    "for i in range(5):\n",
    "    data_train, data_test, target_train, target_test = sk_split(data_matrix,target,test_size=0.2)\n",
    "    forest = Forest(n_estimators=50, criterion='gini', n_jobs=4,verbose=True,max_features=10,oob_score=True,\n",
    "                    min_samples_split=7)\n",
    "    forest.fit(data_train,target_train)\n",
    "    print forest.score(data_test,target_test)\n",
    "    pi = permutation_importance(forest,data_test,target_test)\n",
    "    current += [pi]\n",
    "zscores = np.sqrt(len(current))*np.mean(current,axis=0)/np.std(current,axis=0)\n",
    "plt.figure()\n",
    "plt.bar(range(len(list(train_data.columns))),np.mean(current,axis=0),yerr=np.std(current,axis=0)/np.sqrt(len(current)),error_kw=dict(ecolor='red'))\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(np.arange(len(list(train_data.columns)))+0.4)\n",
    "ax.set_xticklabels(list(train_data.columns))\n",
    "#plt.plot(zscores)\n",
    "bad_features = np.array(train_data.columns)[pi/np.max(pi)<=-0.00]\n",
    "bad_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['longitude_r6', 'funder__Rwssp', 'funder__District Council',\n",
       "       'funder__0', 'funder__Germany Republi', 'funder__Tcrs',\n",
       "       'installer__Commu', 'installer__DANIDA', 'installer__0',\n",
       "       'installer__TCRS', 'installer__Central government',\n",
       "       'installer__CES', 'public_meeting__was_nan', 'permit__was_nan',\n",
       "       'extraction_type__swn 80', 'extraction_type__afridev',\n",
       "       'extraction_type__ksb', 'management__parastatal',\n",
       "       'payment__unknown', 'water_quality__soft', 'water_quality__milky',\n",
       "       'quantity__unknown'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_pi = np.mean(current,axis=0)\n",
    "small_mask = np.abs(mean_pi)<=0.0003\n",
    "small_features = np.array(train_data.columns)[small_mask]\n",
    "small_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.bar(range(len(list(train_data.columns))),np.mean(current,axis=0),yerr=np.std(current,axis=0)/np.sqrt(len(current)),error_kw=dict(ecolor='red'))\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(np.arange(len(list(train_data.columns)))+0.4)\n",
    "ax.set_xticklabels(list(train_data.columns))\n",
    "plt.plot(zscores)\n",
    "bad_features = np.array(train_data.columns)[pi/np.max(pi)<=-0.00]\n",
    "bad_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['random_1', 'random_2', 'random_3', 'random_4'], dtype=object)"
      ]
     },
     "execution_count": 860,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_features = np.array(train_data.columns)[np.mean(current,axis=0)<=0.03]\n",
    "print len(bad_features)/(1.0*len(list(train_data.columns)))\n",
    "bad_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropped_after_87= ['funder__Rwssp', 'installer__0', 'region__Manyara',\n",
    "       'lga__Kigoma Rural', 'public_meeting__was_nan',\n",
    "       'scheme_management__Water Board', 'payment__pay monthly',\n",
    "       'waterpoint_type__improved spring']\n",
    "dropped_after_79 = ['funder__Danida', 'installer__TCRS',\n",
    "       'basin__Lake Victoria', 'lga__Ngara']\n",
    "dropped_after_75 = ['region__Kilimanjaro',\n",
    "       'region__Dar es Salaam', 'scheme_management__Company',\n",
    "       'extraction_type_class__submersible', 'management__other',\n",
    "       'payment__other', 'quantity__unknown', 'source__lake']\n",
    "dropped_after_67 = ['funder__Hesawa', 'funder__World Bank',\n",
    "       'funder__World Vision', 'installer__DWE', 'basin__Pangani',\n",
    "       'basin__Ruvuma / Southern Coast', 'region__Kigoma',\n",
    "       'lga__Moshi Rural', 'lga__Singida Rural', 'lga__Kibondo',\n",
    "       'scheme_management__Private operator', 'permit__was_nan',\n",
    "       'extraction_type_class__other', 'quality_group__salty',\n",
    "       'quantity__seasonal', 'source__rainwater harvesting',\n",
    "       'source_type__rainwater harvesting', 'waterpoint_type__hand pump',\n",
    "       'waterpoint_type_group__improved spring']\n",
    "dropped_after_48 = ['region_code__r20',\n",
    "       'lga__Mvomero', 'lga__Ulanga', 'extraction_type_group__afridev']\n",
    "dropped_after_44 = ['lga__Kilosa',\n",
    "       'lga__Kahama', 'scheme_management__WUG',\n",
    "       'scheme_management__was_nan', 'extraction_type_group__mono',\n",
    "       'management_group__commercial', 'payment_type__per bucket']\n",
    "dropped_after_37 = ['funder__Dwsp',\n",
    "       'installer__Government', 'scheme_name__K', 'permit__True',\n",
    "       'extraction_type__gravity', 'extraction_type__ksb']\n",
    "dropped_after_31 = ['extraction_type__other', 'extraction_type_group__other',\n",
    "       'water_quality__unknown', 'waterpoint_type_group__other']\n",
    "dropped_after_27 = ['public_meeting__False', 'scheme_name__was_nan',\n",
    "       'extraction_type__nira/tanira', 'payment__unknown',\n",
    "       'quantity__insufficient', 'source__machine dbh',\n",
    "       'source_type__spring']\n",
    "dropped_after_20 = ['random_1', 'random_2', 'random_3', 'random_4']\n",
    "remaining = ['amount_tsh',\n",
    " 'date_recorded',\n",
    " 'gps_height',\n",
    " 'longitude',\n",
    " 'latitude',\n",
    " 'district_code',\n",
    " 'population',\n",
    " 'construction_year',\n",
    " 'funder__Government Of Tanzania',\n",
    " 'extraction_type_group__gravity',\n",
    " 'payment_type__never pay',\n",
    " 'quantity__enough',\n",
    " 'quantity__dry',\n",
    " 'waterpoint_type__communal standpipe',\n",
    " 'waterpoint_type__other',\n",
    " 'waterpoint_type__communal standpipe multiple']\n",
    "remaining += ['longitude_r%d'%(i) for i in range(1,r)]\n",
    "remaining += ['latitude_r%d'%(i) for i in range(1,r)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amount_tsh',\n",
       " 'date_recorded',\n",
       " 'gps_height',\n",
       " 'longitude',\n",
       " 'latitude',\n",
       " 'district_code',\n",
       " 'population',\n",
       " 'construction_year',\n",
       " 'funder__Government Of Tanzania',\n",
       " 'extraction_type_group__gravity',\n",
       " 'payment_type__never pay',\n",
       " 'quantity__enough',\n",
       " 'quantity__dry',\n",
       " 'waterpoint_type__communal standpipe',\n",
       " 'waterpoint_type__other',\n",
       " 'waterpoint_type__communal standpipe multiple',\n",
       " 'longitude_r1',\n",
       " 'latitude_r1',\n",
       " 'public_meeting__False',\n",
       " 'scheme_name__was_nan',\n",
       " 'extraction_type__nira/tanira',\n",
       " 'payment__unknown',\n",
       " 'quantity__insufficient',\n",
       " 'source__machine dbh',\n",
       " 'source_type__spring',\n",
       " 'extraction_type__other',\n",
       " 'extraction_type_group__other',\n",
       " 'water_quality__unknown',\n",
       " 'waterpoint_type_group__other',\n",
       " 'funder__Dwsp',\n",
       " 'installer__Government',\n",
       " 'scheme_name__K',\n",
       " 'permit__True',\n",
       " 'extraction_type__gravity',\n",
       " 'extraction_type__ksb',\n",
       " 'lga__Kilosa',\n",
       " 'lga__Kahama',\n",
       " 'scheme_management__WUG',\n",
       " 'scheme_management__was_nan',\n",
       " 'extraction_type_group__mono',\n",
       " 'management_group__commercial',\n",
       " 'payment_type__per bucket',\n",
       " 'region_code__r20',\n",
       " 'lga__Mvomero',\n",
       " 'lga__Ulanga',\n",
       " 'extraction_type_group__afridev',\n",
       " 'funder__Hesawa',\n",
       " 'funder__World Bank',\n",
       " 'funder__World Vision',\n",
       " 'installer__DWE',\n",
       " 'basin__Pangani',\n",
       " 'basin__Ruvuma / Southern Coast',\n",
       " 'region__Kigoma',\n",
       " 'lga__Moshi Rural',\n",
       " 'lga__Singida Rural',\n",
       " 'lga__Kibondo',\n",
       " 'scheme_management__Private operator',\n",
       " 'permit__was_nan',\n",
       " 'extraction_type_class__other',\n",
       " 'quality_group__salty',\n",
       " 'quantity__seasonal',\n",
       " 'source__rainwater harvesting',\n",
       " 'source_type__rainwater harvesting',\n",
       " 'waterpoint_type__hand pump',\n",
       " 'waterpoint_type_group__improved spring',\n",
       " 'region__Kilimanjaro',\n",
       " 'region__Dar es Salaam',\n",
       " 'scheme_management__Company',\n",
       " 'extraction_type_class__submersible',\n",
       " 'management__other',\n",
       " 'payment__other',\n",
       " 'quantity__unknown',\n",
       " 'source__lake',\n",
       " 'funder__Danida',\n",
       " 'installer__TCRS',\n",
       " 'basin__Lake Victoria',\n",
       " 'lga__Ngara',\n",
       " 'funder__Rwssp',\n",
       " 'installer__0',\n",
       " 'region__Manyara',\n",
       " 'lga__Kigoma Rural',\n",
       " 'public_meeting__was_nan',\n",
       " 'scheme_management__Water Board',\n",
       " 'payment__pay monthly',\n",
       " 'waterpoint_type__improved spring']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = remaining + dropped_after_27 + dropped_after_31 + dropped_after_37 + dropped_after_44 + dropped_after_48 + dropped_after_67 + dropped_after_75 + dropped_after_79 + dropped_after_87\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "not_features = np.setdiff1d(list(train_data.columns),features)\n",
    "for f in not_features:\n",
    "    train_data.drop(f,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for bf in bad_features[:]:\n",
    "    train_data.drop(bf,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remaining = train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amount_tsh',\n",
       " 'date_recorded',\n",
       " 'gps_height',\n",
       " 'longitude',\n",
       " 'latitude',\n",
       " 'district_code',\n",
       " 'population',\n",
       " 'construction_year',\n",
       " 'funder__Government Of Tanzania',\n",
       " 'extraction_type_group__gravity',\n",
       " 'payment_type__never pay',\n",
       " 'quantity__enough',\n",
       " 'quantity__dry',\n",
       " 'waterpoint_type__communal standpipe',\n",
       " 'waterpoint_type__other',\n",
       " 'waterpoint_type__communal standpipe multiple']"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(remaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4]; a[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trees = forest.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.34600000e+04,   7.69200000e+03,   6.95800000e+03, ...,\n",
       "         2.00000000e+00,   1.00000000e+00,   3.00000000e+00])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.tree_.weighted_n_node_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.tree.tree.DecisionTreeClassifier"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=18, max_leaf_nodes=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            random_state=311854994, splitter='random')"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.set_params(splitter='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47520,)"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.indices_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30062"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(tree.indices_,dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current = current[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n",
      "131\n",
      "131\n"
     ]
    }
   ],
   "source": [
    "for c in current:\n",
    "    print len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f007995b610>]"
      ]
     },
     "execution_count": 882,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(); plt.plot(train_data.population,train_data.construction_year,'ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0075bc1b90>]"
      ]
     },
     "execution_count": 877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(); plt.plot(np.array(train_data.construction_year),'ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49546021,  0.26091467],\n",
       "       [ 0.26091467,  2.01839352]])"
      ]
     },
     "execution_count": 884,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(train_data.population,train_data.construction_year)/(np.std(train_data.population)*np.std(train_data.construction_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'forest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e31879183acb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'forest' is not defined"
     ]
    }
   ],
   "source": [
    "forest.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 2000 | elapsed:    0.2s remaining:  7.0min\n",
      "[Parallel(n_jobs=4)]: Done 2000 out of 2000 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=10, max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=7,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=4,\n",
       "            oob_score=False, random_state=None, verbose=True,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = Forest(n_estimators=2000, criterion='gini', n_jobs=4,verbose=True,max_features=10,bootstrap=True,\n",
    "                warm_start=False,min_samples_split=7,min_samples_leaf=1,oob_score=False)#True\n",
    "forest.fit(data_matrix,target)\n",
    "#forest.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of 1000 | elapsed:    0.2s remaining:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:   50.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features=10, max_leaf_nodes=None,\n",
       "           min_samples_leaf=1, min_samples_split=7,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=4,\n",
       "           oob_score=False, random_state=None, verbose=True,\n",
       "           warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eforest = EForest(n_estimators=1000, criterion='gini', n_jobs=4,verbose=True,max_features=10,\n",
    "                  min_samples_split=7,bootstrap=False)\n",
    "eforest.fit(data_matrix,target)\n",
    "#eforest.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'oob_decision_function_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-209-39a7c4b19cd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moob_decision_function_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'oob_decision_function_'"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    p = np.argmax(forest.oob_decision_function_,axis=1)\n",
    "    print i, \" \", np.sum((target==i)&(p==i))/np.sum(target==i,dtype=np.float)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   1 out of  13 | elapsed:    0.5s remaining:    6.0s\n",
      "[Parallel(n_jobs=4)]: Done 2000 out of 2000 | elapsed:   47.9s finished\n"
     ]
    }
   ],
   "source": [
    "predictions = forest.predict(data_matrix_compete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_for_export = np.zeros(predictions.shape,dtype=np.object)\n",
    "predictions_for_export[predictions==0] = 'non functional'\n",
    "predictions_for_export[predictions==1] = 'functional needs repair'\n",
    "predictions_for_export[predictions==2] = 'functional'\n",
    "predictions_for_export = np.array([compete_id, predictions_for_export]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14850, 2)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_for_export.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50785, 'non functional'],\n",
       "       [51630, 'functional'],\n",
       "       [17168, 'functional'],\n",
       "       ..., \n",
       "       [28749, 'functional'],\n",
       "       [33492, 'functional'],\n",
       "       [68707, 'non functional']], dtype=object)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_for_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"submit9.csv\",predictions_for_export,fmt='%s',delimiter=',',header='id,status_group')\n",
    "##### REMEMBER: EDIT CSV FILE TO REMOVE HEADER'S LEADING # AND SPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
